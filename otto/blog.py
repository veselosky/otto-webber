# encoding: UTF-8
"""Simple blog manager.

General Introduction
====================
Conceptually, a blog is a Channel optionally containing Entries and Channels. A
Channel is simply a directory containing a valid `channel.json` file. An Entry
is a file of the correct EntryType (see under Inputs below).

All objects are represented as simple dictionaries. This ensures they can
easily be serialized to and from JSON, the canonical storage format. The
dictionaries are designed to be compatible with those produced by feedparser_.
Consult the feedparser documentation for hints as to useful keys. However,
arbitrary keys are accepted as generic metadata and passed to your template
context unchanged, so long as they do not conflict with (or are compatible
with) feedparser reserved names.

Dictionary keys beginning with an underscore are not stored, but are calculated
and inserted by the load routines. Such keys are not guaranteed to exist. Do
not set them yourself.

Dealing with datetimes is currently a massive pain. I haven't decided how to
deal with them yet. Inputs SHOULD be represented as RFC3339 (i.e. ISO-8601
formatted) strings. Otto attempts to normalize datetime values to that format,
but makes no promises. Outputs are not guaranteed to be in any particular
format, though they MAY be parsable with `dateutil.parser`. The "*_parsed" keys
provided by feedparser MAY exist, but do not count on it.  A list of fields
expected to contain datetimes is defined in the module variable
`DATETIME_FIELDS`. 

Inputs
------
All files under the blog channel are considered inputs. All input files are
passed to the output unchanged. Two types of inputs are treated specially:
Channels and Entries. Each input of these types is processed to produce a
separate output file for each configured output format. In the future, output
formats will be configurable. Currently, they are hard-coded to include: JSON,
HTML, and Atom.

A Channel is a directory containing a valid `channel.json` file at its top
level.  The `channel.json` file contains metadata about the Channel which Otto
uses to compose the Channel. It is equivalent to a feedparser "feed" object,
and keys are interpreted with the same semantics. As a metadata file,
`channel.json` is not processed directly into alternate output formats.
However, for each Channel, Otto produces an "index" output of each format,
containing the Channel metadata and the 50 most recent entries in that channel
(but excluding entries in any sub-channels).

An Entry is any file within a Channel that matches a valid EntryType for that
Channel. In future this will be configurable. Currently, the only valid EntryTypes
are Markdown files ('*.md') and JSON files ('*.json'). Markdown inputs are processed
with the 'codehilite', 'extra', and 'meta' extensions.

Outputs
-------
For each Entry or Channel input, Otto will produce an output in each of the
configured output formats. In the future, output formats will be configurable.
Currently, they are hard-coded to include: JSON, HTML, and Atom. The output
will have an identical file name, but with the file extension converted to one
appropriate for the format ('.json', '.html', '.atom').  If you use multiple
extensions to take advantage of Apache's content negotiation, ensure the file
type extension is the LAST one. Otherwise Otto will not recognize it.

JSON output is generated using a custom JSON serializer. Sorry, no user customization
available at this time.

Atom output is generated by Jinja2 templates. At some point in the future,
it may change to use a proper XML generator. Until then, this output may be
somewhat fragile, but should work in the general case.

HTML output is generated using Jinja2 templates. To supply your own templates,
set `env['otto.template_dir']` to their location. Otherwise, Otto will use its
own rather spartan POSH templates (POSH = Plain Old Semantic HTML).

"""
from datetime import datetime
from dateutil import tz, parser as dateparser
from fabric.api import env, lcd, local, require, task as fabtask
from jinja2 import Environment, FileSystemLoader
import json
import markdown
import os
import os.path
from otto.util import ancestor_of, slurp, dump, json_dump

DATETIME_FIELDS = ['created', 'date', 'expired', 'published', 'updated']
# TODO Factor out a date normalization function.


# base_dir here is really the DocRoot.
# base_dir and base_url feel like hacks.
# TODO Rationalize the filepath and urlpath for Channel and Entry objects.
def load_channel(path, base_dir, base_url):
    """Return a channel dict loaded from the given path"""
    # Path normalization
    filename = path
    if os.path.isdir(filename):
        filename = os.path.join(filename, 'channel.json')
    if not os.path.exists(filename):
        raise ValueError('Cannot load channel from non-existent path "%s"' % filename)

    channel = json.loads(slurp(filename))
    channel['_filename'] = filename
    channel['_dirname'] = os.path.dirname(filename)
    channel['_path'] = os.path.relpath(channel['_dirname'], base_dir)
    channel['_url'] = base_url if channel['_path'] == '.' else base_url+channel['_path']+'/'
    # TODO Normalize datetime fields in the Channel object.
    # TODO Return Channel as FeedParserDict
    return channel


def load_entry_markdown(filename):
    """Return an entry dict loaded from the given path."""
    # Path normalization
    basename, ext = os.path.splitext(filename)
    channel_dir = ancestor_of(filename, containing='channel.json')

    # Do the parsing
    md = markdown.Markdown(
            extensions=['codehilite', 'extra', 'meta'],
            output_format='html4',
            )
    text = slurp(filename)
    body = md.convert(text)
    metadata = md.Meta

    # Markdown makes every value a list, just in case. I only want lists if the
    # thing claims to be a list.
    entry = {}
    for k,v in metadata.iteritems():
        if len(v) == 1 and not k.endswith('_list'):
            entry[k] = v[0]
        else:
            entry[k] = v
        # TODO Move entry datetime normalization to shared function.
        # For any fields containing datetimes, ensure they are fully qualified
        # RFC3339 formatted strings (input is likely to contain date only with
        # no timezone info, e.g. '2011-09-30').
        if k in DATETIME_FIELDS:
            default = datetime.now(tz.gettz()).replace(hour=0,minute=0,second=0,microsecond=0)
            dt = dateparser.parse(entry[k], default=default)
            entry[k] = dt.isoformat()

    # TODO Make entry.content compatible with feedparser's entry.content
    # http://packages.python.org/feedparser/reference-entry-content.html
    entry['content'] = body

    # These properties are contextual, therefore calculated and not stored.
    mtime = datetime.utcfromtimestamp(os.path.getmtime(filename)).isoformat()+'Z'
    entry['_modified'] = mtime
    entry['_filename'] = filename
    entry['_path'] = os.path.relpath(basename, channel_dir)
    # TODO Return Entry as FeedParserDict
    return entry


# TODO Create md2json function.
# TODO Create json2atom function.
# TODO Create json2html function.

# TODO INCREMENTAL BUILD
# Allow a datetime to be passed. Only files touched after that time will be processed.
# This can be stored in the Channel.updated field.
# First find all the markdown files, and convert them to JSON ONLY if they
# are newer than the existing JSON file (or no JSON file exists).
# Second, walk the blog DEPTH FIRST (not TopDown as before).
# For each step:
#   - Process all the JSON entries, producing HTML and Atom output ONLY if needed.
#   - Append each JSON entry processed to the tempChannellist.
#   - If thisdir is the Channel:
#       - If build is incremental, merge loaded ChannelList with tempChannelList
#       - generate Channel outputs
#       - PURGE the tempChannelList

@fabtask
def build_blog(blogdir):
    """Build the blog"""
    blogname = os.path.basename(blogdir)
    entries_for_channel = {} # blog can have multiple channels

    # All the directories and paths we will need for ins and outs
    require('otto.build_dir', 'otto.template_dir', 'otto.site')
    build_dir = os.path.join(env['otto.build_dir'], 'htdocs', blogname)
    template_dir = env['otto.template_dir']
    # FIXME How to tell if absolute links should be http or https?
    blog_url = 'http://%s/%s/' % (env['otto.site'], blogname)

    test_root = os.path.dirname(env['real_fabfile'])
    with lcd(test_root):
        local('mkdir -p %s' % build_dir)
        local('cp -a %s %s' % (blogdir+'/', build_dir))

    jinja = Environment(loader=FileSystemLoader(template_dir),
            extensions=['jinja2.ext.loopcontrols', 'jinja2.ext.autoescape'])

    for thisdir, subdirs, files in os.walk(build_dir):
        channel_dir = ancestor_of(thisdir, containing='channel.json')
        channel = load_channel(channel_dir, build_dir, blog_url)
        entries_for_channel.setdefault(channel['_filename'], [])
        for entryfile in files:
            if not entryfile.endswith('.md'):
                continue
            entrypath = os.path.join(thisdir, entryfile)
            outpath, ext = os.path.splitext(entrypath)

            # Load entry, Add to entrylist for its channel
            entry = load_entry_markdown(entrypath)
            entries_for_channel[channel['_filename']].append(entry)

            # TODO Abstraction around Formatters, so you can configure any kind
            # of output using a plugin.

            # write JSON output
            json_dump(entry, outpath+'.json')

            # Write HTML output (entry or channel may specify a template)
            template_name = entry.get('template', None) or \
                channel.get('entry_template', None) or \
                env['otto.blog.entry_template']
            template = jinja.get_template(template_name)
            context = {'entry':entry, 'channel':channel}
            dump(template.render(context), outpath+'.html')

    # Now we've accumulated all the entries. Write the channel indexes.
    for channelfile, entries in entries_for_channel.iteritems():
        channel = load_channel(channelfile, build_dir, blog_url)
        outpath = os.path.join(channel['_dirname'], 'index')

        def entry_sort_key(e):
            return e.get('updated', None) or e.get('published', None) or e.get('date', None)
        # sort entries reverse chrono
        entries.sort(key=entry_sort_key, reverse=True)
        channel['entries'] = entries

        # dump index.json
        json_dump(channel, outpath+'.json')

        context = {'channel': channel}

        # render index.html template
        template_name = channel.get('index_template', None) or \
            env['otto.blog.channel_template']
        template = jinja.get_template(template_name)
        dump(template.render(context), outpath+'.html')

        # render FEED template(s)
        feed_template = jinja.get_template('index.atom')
        dump(feed_template.render(context), outpath+'.atom')

